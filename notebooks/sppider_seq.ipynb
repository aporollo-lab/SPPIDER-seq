{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q86j0R688No0",
    "outputId": "2a09995a-c1a4-46d7-cea7-d403def97499"
   },
   "outputs": [],
   "source": [
    "#@title Setup **SPPIDER-seq** (~5min)\n",
    "%%time\n",
    "\n",
    "print(\"Installing libraries and importing dependencies...\")\n",
    "\n",
    "# Install Required Libraries\n",
    "!pip install transformers biopython torch --quiet\n",
    "\n",
    "# Import Dependencies\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "from itertools import product\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub\")\n",
    "\n",
    "# Upload Pretrained Models\n",
    "\n",
    "print(\"Copying the PPI prediction models...\")\n",
    "\n",
    "# Create virtual folders on Colab\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Copy the models to Colab\n",
    "!curl -sS -L \"https://sppider.cchmc.org/models/best_model-AH16_EP10-PEP2REC_DR01_CHUNKS-Iter22.pt\" -o models/peptide_model.pt\n",
    "!curl -sS -L \"https://sppider.cchmc.org/models/best_model-AH16_EP10-REC2PEP_DR01_CHUNKS-Iter24.pt\" -o models/receptor_model.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Hm_6KmTZKTyq"
   },
   "outputs": [],
   "source": [
    "#@title Function Definitions\n",
    "\n",
    "# Define global variables\n",
    "\n",
    "# Track all prediction sessions\n",
    "output_sessions = []\n",
    "current_output_folder = None\n",
    "\n",
    "\n",
    "# Define functions\n",
    "\n",
    "# Embedding Utilities\n",
    "def parse_fasta(text):\n",
    "    records = list(SeqIO.parse(StringIO(text.strip()), \"fasta\"))\n",
    "    return [(i, rec.id, str(rec.seq)) for i, rec in enumerate(records)]\n",
    "\n",
    "def embed_sequence_chunks(model, tokenizer, sequence, seq_name, max_len=1024, stride=512):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    tokens = tokenizer(sequence, return_tensors='pt', truncation=False)['input_ids'][0]\n",
    "\n",
    "    chunk_data = []\n",
    "    for i in range(0, len(tokens), stride):\n",
    "        chunk = tokens[i:i + max_len]\n",
    "        if chunk.size(0) < 2:\n",
    "            continue\n",
    "\n",
    "        input_ids = chunk.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids, output_hidden_states=True)\n",
    "            emb = out.last_hidden_state[:, 1:-1, :]  # Remove CLS and EOS\n",
    "\n",
    "        tokens_decoded = tokenizer.convert_ids_to_tokens(chunk[1:-1])\n",
    "        aa_seq = \"\".join(t.replace(\"\\u2581\", \"\") for t in tokens_decoded)\n",
    "\n",
    "        chunk_data.append({\n",
    "            \"chunk_start\": i,\n",
    "            \"chunk_end\": i + max_len,\n",
    "            \"chunk_seq\": aa_seq,\n",
    "            \"embedding\": emb.squeeze(0).cpu()\n",
    "        })\n",
    "\n",
    "    return chunk_data\n",
    "\n",
    "# Embedding Workflow\n",
    "def run_embedding_workflow(btn):\n",
    "    global current_output_folder, output_sessions\n",
    "    global all_pair_chunks\n",
    "    all_pair_chunks = []\n",
    "\n",
    "    with output_box:\n",
    "        output_box.clear_output()\n",
    "\n",
    "        # Create timestamped output folder\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        current_output_folder = f\"outputs/{timestamp}\"\n",
    "        os.makedirs(current_output_folder, exist_ok=True)\n",
    "        output_sessions.append(current_output_folder)\n",
    "\n",
    "        print(\"\\nLoading ESM-2 model...\")\n",
    "        model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "        tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "        model = EsmModel.from_pretrained(model_name).eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        print(\"\\nParsing FASTA inputs...\")\n",
    "        seqs1 = parse_fasta(query_seq_input.value)\n",
    "        seqs2 = parse_fasta(partner_seq_input.value)\n",
    "\n",
    "        pairs = list(product(seqs1, seqs2))\n",
    "\n",
    "        for (i1, id1, s1), (i2, id2, s2) in pairs:\n",
    "            print(f\"\\nGenerating embeddings for the pair: {id1} vs {id2}\")\n",
    "            rec_chunks = embed_sequence_chunks(model, tokenizer, s1, id1)\n",
    "            lig_chunks = embed_sequence_chunks(model, tokenizer, s2, id2)\n",
    "\n",
    "            print(f\"  → {len(rec_chunks)} receptor chunks\")\n",
    "            print(f\"  → {len(lig_chunks)} ligand chunks\")\n",
    "\n",
    "            # global all_pair_chunks\n",
    "            # if 'all_pair_chunks' not in globals():\n",
    "            #     all_pair_chunks = []\n",
    "\n",
    "            all_pair_chunks.append({\n",
    "                \"receptor_id\": id1,\n",
    "                \"ligand_id\": id2,\n",
    "                \"receptor_seq\": s1,\n",
    "                \"ligand_seq\": s2,\n",
    "                \"receptor_chunks\": rec_chunks,\n",
    "                \"peptide_chunks\": lig_chunks\n",
    "            })\n",
    "\n",
    "        print(\"\\nRunning PPI predictions...\")\n",
    "        run_ppi_predictions(peptide_model_path=\"models/peptide_model.pt\",\n",
    "                            receptor_model_path=\"models/receptor_model.pt\",\n",
    "                            output_dir=current_output_folder)\n",
    "\n",
    "# Load Model Architecture\n",
    "class CrossAttentionLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, query, context, context_mask=None):\n",
    "        attn_output, _ = self.cross_attn(query, context, context, key_padding_mask=context_mask)\n",
    "        return self.norm(query + attn_output)\n",
    "\n",
    "class ChunkwiseInteractionModel(nn.Module):\n",
    "    def __init__(self, embed_dim=1280, num_heads=16, initial_bias=None):\n",
    "        super().__init__()\n",
    "        self.cross_attn = CrossAttentionLayer(embed_dim, num_heads)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(embed_dim, 1)\n",
    "        )\n",
    "        if initial_bias is not None:\n",
    "            self.mlp[-1].bias.data.fill_(initial_bias)\n",
    "\n",
    "    def forward(self, chunks_A, chunks_B, stride=512):\n",
    "        position_logits = {}\n",
    "        for i, a_chunk in enumerate(chunks_A):\n",
    "            if a_chunk.ndim == 2:\n",
    "                a_chunk = a_chunk.unsqueeze(0)\n",
    "\n",
    "            all_logits = []\n",
    "            for b_chunk in chunks_B:\n",
    "                if b_chunk.ndim == 2:\n",
    "                    b_chunk = b_chunk.unsqueeze(0)\n",
    "\n",
    "                context_mask = (b_chunk.abs().sum(dim=-1) == 0)\n",
    "                x = self.cross_attn(a_chunk, b_chunk, context_mask=context_mask)\n",
    "                logits = self.mlp(x).squeeze(0).squeeze(-1)\n",
    "\n",
    "                if len(all_logits) > 0:\n",
    "                    max_len = max(l.shape[0] for l in all_logits)\n",
    "                    if logits.shape[0] < max_len:\n",
    "                        pad_size = max_len - logits.shape[0]\n",
    "                        logits = torch.cat([logits, torch.zeros(pad_size, device=logits.device)], dim=0)\n",
    "                all_logits.append(logits)\n",
    "\n",
    "            pooled_logits = torch.max(torch.stack(all_logits, dim=0), dim=0).values\n",
    "            start = i * stride\n",
    "            for j in range(pooled_logits.shape[0]):\n",
    "                pos = start + j\n",
    "                if pos not in position_logits:\n",
    "                    position_logits[pos] = []\n",
    "                position_logits[pos].append(pooled_logits[j])\n",
    "\n",
    "        return position_logits\n",
    "\n",
    "# Predict PPI from a Given Pair\n",
    "def predict_probs(chunks_A, chunks_B, model_path, seq_len, stride=512):\n",
    "    model = ChunkwiseInteractionModel().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    A_embs = [x.to(device) for x in chunks_A]\n",
    "    B_embs = [x.to(device) for x in chunks_B]\n",
    "\n",
    "    position_logits = model(A_embs, B_embs)\n",
    "    full_probs = np.zeros(seq_len)\n",
    "    for pos in range(seq_len):\n",
    "        if pos in position_logits:\n",
    "            logits = torch.stack(position_logits[pos])\n",
    "            full_probs[pos] = torch.sigmoid(logits).max().item()\n",
    "    return full_probs\n",
    "\n",
    "# File saving functions\n",
    "def sanitize_filename(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9_.-]', '_', text)\n",
    "\n",
    "def save_probabilities(filename, seq_id, partner_id, model_type, sequence, probabilities):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"# Query:{seq_id} Partner:{partner_id} Model:{model_type}-centric\\n\")\n",
    "        f.write(\"Position\\tAminoAcid\\tProbability\\n\")\n",
    "        for i, (aa, prob) in enumerate(zip(sequence, probabilities), 1):\n",
    "            f.write(f\"{i}\\t{aa}\\t{prob:.3f}\\n\")\n",
    "\n",
    "# Run PPI Predictions\n",
    "def run_ppi_predictions(peptide_model_path=\"models/peptide_model.pt\",\n",
    "                        receptor_model_path=\"models/receptor_model.pt\",\n",
    "                        output_dir=\"outputs\"):\n",
    "    for i, pair in enumerate(all_pair_chunks):\n",
    "        rec_id, pep_id = pair['receptor_id'], pair['ligand_id']\n",
    "        rec_seq, pep_seq = pair['receptor_seq'], pair['ligand_seq']\n",
    "        rec_chunks = [c[\"embedding\"] for c in pair[\"receptor_chunks\"]]\n",
    "        pep_chunks = [c[\"embedding\"] for c in pair[\"peptide_chunks\"]]\n",
    "\n",
    "        print(f\"[{i+1}/{len(all_pair_chunks)}] Predicting for: {rec_id} ↔ {pep_id}\")\n",
    "\n",
    "        probs_peptide = predict_probs(rec_chunks, pep_chunks, peptide_model_path, len(rec_seq))\n",
    "        probs_receptor = predict_probs(rec_chunks, pep_chunks, receptor_model_path, len(rec_seq))\n",
    "\n",
    "        # Save results\n",
    "\n",
    "        # Safe filenames\n",
    "        safe_rec_id = sanitize_filename(rec_id)\n",
    "        safe_pep_id = sanitize_filename(pep_id)\n",
    "\n",
    "        # Save detailed output\n",
    "        pep_file = os.path.join(output_dir, f\"{safe_rec_id}__{safe_pep_id}__peptide_centric.txt\")\n",
    "        rec_file = os.path.join(output_dir, f\"{safe_rec_id}__{safe_pep_id}__receptor_centric.txt\")\n",
    "        save_probabilities(pep_file, rec_id, pep_id, \"peptide\", rec_seq, probs_peptide)\n",
    "        save_probabilities(rec_file, rec_id, pep_id, \"receptor\", rec_seq, probs_receptor)\n",
    "\n",
    "        # Generate a combined plot, show it and save to a file\n",
    "        fig_name = os.path.join(output_dir, f\"{safe_rec_id}__{safe_pep_id}__plot.png\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(probs_receptor, label=\"Receptor-Centric\", color='orange')\n",
    "        plt.plot(probs_peptide, label=\"Peptide-Centric\", linestyle='--', color='blue')\n",
    "        plt.title(f\"Receptor PPI Site Probabilities\\nQuery: {rec_id} | Partner: {pep_id}\")\n",
    "        plt.xlabel(\"Receptor Residue Position\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_name)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294,
     "referenced_widgets": [
      "24f5d98b42de40a4a8cb7185c8b1a86e",
      "949ebedb86cc43c4a4cd4bdf50489362",
      "160a5b0f76a54017bc60b2b70c571839",
      "748875bfde114f96915902fdaa3d6eb2",
      "7845c166fdb148bebfb3a164b11a6131",
      "329284073af844b4a2944d90deb116d1",
      "a01f887008e7428d9de7764a7adea313",
      "ae69e3ad2d764b75a9d62c38aef7e0ab",
      "7c29df2741584c288cb8010468d5c0e1",
      "7a584a808d8543eca04b403061f406bb",
      "b48b474448ea4c19bd2547a58307c956"
     ]
    },
    "id": "tn3U2MYL8gcp",
    "outputId": "1a6f94dc-e229-4e23-c303-6d9361c45df8"
   },
   "outputs": [],
   "source": [
    "#@title Input Form\n",
    "# Process Input and Run Predictions\n",
    "\n",
    "# Input FASTA Sequences from User\n",
    "query_seq_input = ipw.Textarea(\n",
    "    value='>query\\nMKTFFVGLAALVTMATGVHS',\n",
    "    description='Query',\n",
    "    layout=ipw.Layout(width='80%', height='100px')\n",
    ")\n",
    "\n",
    "partner_seq_input = ipw.Textarea(\n",
    "    value='>partner\\nMTEITAAMVKELRESTGAGM',\n",
    "    description='Partner(s)',\n",
    "    layout=ipw.Layout(width='80%', height='100px')\n",
    ")\n",
    "\n",
    "run_button = ipw.Button(description=\"Run PPI predictions\")\n",
    "output_box = ipw.Output()\n",
    "\n",
    "display(Markdown(\"### Input your query and partner protein sequences in FASTA format\"))\n",
    "display(query_seq_input, partner_seq_input, run_button, output_box)\n",
    "\n",
    "run_button.on_click(run_embedding_workflow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411,
     "referenced_widgets": [
      "6a9922ec92a24d148a8f56a96ccef674",
      "98e58e5b7c154293be78f880259dd813",
      "76b96314f7364d69a74aadcdd09ec623",
      "590d003689724516a404b10788264cf7",
      "e23865f6ddbc47c3a7ea6d33452eab15",
      "0d7a8cd4c59b48a5b268b1aeae8d2c0f",
      "f29938741cd9449cbfa8b33e5cef4c36",
      "4181199a7837485eba7c886aab36a202",
      "a4f296a094354607a38517506f327f2f",
      "9fec7a1cebe148f88b8753e170ea0cc8",
      "283ada8768754abd8692e526357f2967",
      "f343af8021f148968d9b7ab7e3311580"
     ]
    },
    "id": "vLr6-pcrUA_X",
    "outputId": "32d93489-07bc-4fe9-c5d4-03237fb1301c"
   },
   "outputs": [],
   "source": [
    "#@title Review and Download Results\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from IPython.display import FileLink, display\n",
    "from google.colab import files\n",
    "\n",
    "# Widget containers\n",
    "view_box = ipw.Output()\n",
    "download_button = ipw.Button(description=\"⬇️ Download All Files\", button_style='success')\n",
    "download_button.layout.display = 'none'  # Hidden until selection\n",
    "current_zip_path = {\"path\": None}\n",
    "\n",
    "# Create ZIP inside outputs/ folder\n",
    "def create_zip(folder):\n",
    "    base_name = os.path.basename(folder.rstrip(\"/\"))\n",
    "    zip_path = f\"{folder.rstrip('/')}.zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for file in glob(f\"{folder}/*\"):\n",
    "            arcname = os.path.basename(file)\n",
    "            zipf.write(file, arcname=arcname)\n",
    "    return zip_path\n",
    "\n",
    "# Dropdown callback\n",
    "def on_select_run(change):\n",
    "    folder = change['new']\n",
    "    if not folder:\n",
    "        view_box.clear_output()\n",
    "        download_button.layout.display = 'none'\n",
    "        return\n",
    "\n",
    "    with view_box:\n",
    "        view_box.clear_output()\n",
    "        print(f\"📂 Files in: {folder}\")\n",
    "        for f in sorted(glob(f\"{folder}/*\")):\n",
    "            print(f\"• {os.path.basename(f)}\")\n",
    "\n",
    "        # Create ZIP file\n",
    "        zip_path = create_zip(folder)\n",
    "        current_zip_path[\"path\"] = zip_path\n",
    "        download_button.description = f\"Download All ({os.path.basename(zip_path)})\"\n",
    "        download_button.layout.display = 'inline-block'\n",
    "        download_button.layout=ipw.Layout(width='300px')\n",
    "\n",
    "# Download button click handler\n",
    "def on_download_clicked(btn):\n",
    "    zip_path = current_zip_path.get(\"path\")\n",
    "    if zip_path and os.path.exists(zip_path):\n",
    "        files.download(zip_path)\n",
    "\n",
    "# Hook up download action\n",
    "download_button.on_click(on_download_clicked)\n",
    "\n",
    "# List all subfolders under outputs/\n",
    "output_sessions = sorted(glob(\"outputs/*/\"))\n",
    "session_selector = ipw.Dropdown(\n",
    "    options=[\"\"] + output_sessions,\n",
    "    description=f'Select query ({len(output_sessions)} found):',\n",
    "    layout=ipw.Layout(min_width='400px', max_width='800px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "session_selector.observe(on_select_run, names='value')\n",
    "\n",
    "# Display UI\n",
    "display(ipw.VBox([session_selector, view_box, download_button]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
